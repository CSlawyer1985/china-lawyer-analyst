#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€é«˜äººæ°‘æ³•é™¢å¸æ³•è§£é‡Šç›‘æµ‹å·¥å…·

åŠŸèƒ½ï¼š
1. ç›‘æµ‹æœ€é«˜æ³•é™¢å®˜ç½‘å‘å¸ƒçš„æœ€æ–°å¸æ³•è§£é‡Š
2. å¯¹æ¯”ç°æœ‰æ¨¡å—ï¼Œè¯†åˆ«æ–°å‘å¸ƒçš„å¸æ³•è§£é‡Š
3. ç”Ÿæˆå¾…å¤„ç†é˜Ÿåˆ—ï¼ˆqueue.jsonï¼‰
4. å‘é€æ›´æ–°é€šçŸ¥

ä½œè€…ï¼šchina-lawyer-analyst é¡¹ç›®ç»„
ç‰ˆæœ¬ï¼šv1.0.0
æœ€åæ›´æ–°ï¼š2026-01-16
"""

import requests
from bs4 import BeautifulSoup
import json
from pathlib import Path
from datetime import datetime, timedelta
import time
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('monitor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# é…ç½®
CONFIG = {
    "supreme_court_url": "http://www.court.gov.cn",
    "interpretation_list_url": "http://www.court.gov.cn/fabu-xiangqing.html",
    "queue_file": "queue.json",
    "existing_modules_file": "interpretations/metadata.json",
    "check_interval_days": 7,  # æ¯å‘¨æ£€æŸ¥ä¸€æ¬¡
    "request_timeout": 30,
    "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
}


class CourtMonitor:
    """æœ€é«˜æ³•é™¢å¸æ³•è§£é‡Šç›‘æµ‹å™¨"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': CONFIG['user_agent']
        })

    def fetch_interpretations(self, days=30):
        """
        è·å–æœ€æ–°å¸æ³•è§£é‡Š

        Args:
            days: è·å–æœ€è¿‘Nå¤©çš„å¸æ³•è§£é‡Šï¼Œé»˜è®¤30å¤©

        Returns:
            list: å¸æ³•è§£é‡Šåˆ—è¡¨
        """
        logger.info(f"å¼€å§‹è·å–æœ€è¿‘ {days} å¤©çš„å¸æ³•è§£é‡Š...")

        try:
            # æ–¹æ¡ˆ1ï¼šå°è¯•ä»å®˜ç½‘ RSS/åˆ—è¡¨é¡µè·å–
            url = CONFIG['interpretation_list_url']
            response = self.session.get(url, timeout=CONFIG['request_timeout'])
            response.raise_for_status()
            response.encoding = 'utf-8'

            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')

            # æå–å¸æ³•è§£é‡Šåˆ—è¡¨
            interpretations = []

            # æ ¹æ®å®é™…HTMLç»“æ„è°ƒæ•´é€‰æ‹©å™¨
            # è¿™é‡Œæä¾›å¤šç§å¯èƒ½çš„CSSé€‰æ‹©å™¨
            possible_selectors = [
                'div.interpretation-item',
                'li.fabu-list',
                'div.list li',
                'ul.news-list li',
                'div.content li'
            ]

            items = None
            for selector in possible_selectors:
                items = soup.select(selector)
                if items:
                    logger.info(f"ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(items)} ä¸ªé¡¹ç›®")
                    break

            if not items:
                logger.warning("æœªèƒ½ä»å®˜ç½‘æå–åˆ—è¡¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                return self._fetch_interpretations_fallback(days)

            # è§£ææ¯ä¸ªé¡¹ç›®
            cutoff_date = datetime.now() - timedelta(days=days)

            for item in items:
                try:
                    # æå–æ ‡é¢˜
                    title_elem = item.find(['h3', 'h4', 'a', 'span'])
                    if not title_elem:
                        continue
                    title = title_elem.get_text(strip=True)

                    # æå–é“¾æ¥
                    link_elem = item.find('a')
                    link = link_elem.get('href', '') if link_elem else ''
                    if link and not link.startswith('http'):
                        link = CONFIG['supreme_court_url'] + link

                    # æå–æ—¥æœŸ
                    date_elem = item.find(['span', 'time', 'div'], class_=lambda x: x and ('date' in str(x).lower() or 'time' in str(x).lower()))
                    date_str = date_elem.get_text(strip=True) if date_elem else ''
                    pub_date = self._parse_date(date_str)

                    # è¿‡æ»¤ï¼šåªä¿ç•™æœ€è¿‘Nå¤©çš„
                    if pub_date and pub_date >= cutoff_date:
                        interpretations.append({
                            'title': title,
                            'link': link,
                            'date': pub_date.strftime('%Y-%m-%d'),
                            'detected_at': datetime.now().isoformat()
                        })

                except Exception as e:
                    logger.warning(f"è§£æé¡¹ç›®æ—¶å‡ºé”™: {e}")
                    continue

            logger.info(f"æˆåŠŸè·å– {len(interpretations)} ä¸ªå¸æ³•è§£é‡Š")
            return interpretations

        except Exception as e:
            logger.error(f"è·å–å¸æ³•è§£é‡Šåˆ—è¡¨å¤±è´¥: {e}")
            return self._fetch_interpretations_fallback(days)

    def _fetch_interpretations_fallback(self, days=30):
        """
        å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å…³é”®è¯æœç´¢

        å½“å®˜ç½‘åˆ—è¡¨é¡µæ— æ³•è®¿é—®æ—¶ä½¿ç”¨
        """
        logger.info("ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºäºå·²çŸ¥å¸æ³•è§£é‡ŠURLæ¨¡å¼")

        # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥è®¿é—®å¸¸è§çš„å¸æ³•è§£é‡ŠURLæ ¼å¼
        # ä¾‹å¦‚ï¼šhttp://www.court.gov.cn/fabu-xiangqing-xxx.html
        interpretations = []

        # è¿™é‡Œå¯ä»¥æ·»åŠ å·²çŸ¥çš„å¸æ³•è§£é‡ŠURLæ¨¡å¼
        # å®é™…ä½¿ç”¨æ—¶éœ€è¦æ ¹æ®å®˜ç½‘ç»“æ„è°ƒæ•´

        return interpretations

    def _parse_date(self, date_str):
        """
        è§£ææ—¥æœŸå­—ç¬¦ä¸²

        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚ "2024-01-15" "2024å¹´1æœˆ15æ—¥"

        Returns:
            datetime or None
        """
        if not date_str:
            return None

        # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
        date_formats = [
            '%Y-%m-%d',
            '%Yå¹´%mæœˆ%dæ—¥',
            '%Y/%m/%d',
            '%d-%m-%Y',
        ]

        for fmt in date_formats:
            try:
                return datetime.strptime(date_str, fmt)
            except ValueError:
                continue

        logger.warning(f"æ— æ³•è§£ææ—¥æœŸ: {date_str}")
        return None

    def is_new_interpretation(self, title, date):
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºæ–°å¸æ³•è§£é‡Š

        Args:
            title: å¸æ³•è§£é‡Šæ ‡é¢˜
            date: å‘å¸ƒæ—¥æœŸ

        Returns:
            bool
        """
        # 1. ç”Ÿæˆæ¨¡å—ID
        module_id = self._generate_module_id(title)

        # 2. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨äº interpretations/
        existing_modules_file = Path(CONFIG['existing_modules_file'])
        if existing_modules_file.exists():
            with open(existing_modules_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
                existing_ids = [interp['id'] for interp in metadata.get('interpretations', [])]

            if module_id in existing_ids:
                logger.info(f"{module_id} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                return False

        # 3. æ£€æŸ¥æ˜¯å¦å·²åœ¨é˜Ÿåˆ—ä¸­
        queue_file = Path(CONFIG['queue_file'])
        if queue_file.exists():
            with open(queue_file, 'r', encoding='utf-8') as f:
                queue = json.load(f)
                queued_titles = [item['title'] for item in queue]

            if title in queued_titles:
                logger.info(f"{title} å·²åœ¨é˜Ÿåˆ—ä¸­ï¼Œè·³è¿‡")
                return False

        return True

    def _generate_module_id(self, title):
        """
        æ ¹æ®æ ‡é¢˜ç”Ÿæˆæ¨¡å—ID

        è§„åˆ™ï¼š{area}-{type}-{year}

        ä¾‹å¦‚ï¼š
        - contract-general-2023ï¼ˆåˆåŒç¼–é€šåˆ™è§£é‡Š2023ï¼‰
        - security-law-2020ï¼ˆæ‹…ä¿åˆ¶åº¦è§£é‡Š2020ï¼‰

        Args:
            title: å¸æ³•è§£é‡Šæ ‡é¢˜

        Returns:
            str: æ¨¡å—ID
        """
        # æå–å¹´ä»½
        import re
        year_match = re.search(r'(20\d{2})', title)
        year = year_match.group(1) if year_match else datetime.now().year

        # è¯†åˆ«é¢†åŸŸå’Œç±»å‹
        if 'åˆåŒ' in title:
            area = 'contract'
            type_ = 'general'
        elif 'æ‹…ä¿' in title or 'ä¿è¯' in title:
            area = 'security'
            type_ = 'law'
        elif 'å…¬å¸' in title:
            area = 'corporate'
            type_ = 'law'
        elif 'ä¾µæƒ' in title:
            area = 'tort'
            type_ = 'law'
        else:
            area = 'civil'
            type_ = 'general'

        return f"{area}-{type_}-{year}"

    def save_to_queue(self, interpretations):
        """
        ä¿å­˜åˆ°å¾…å¤„ç†é˜Ÿåˆ—

        Args:
            interpretations: å¸æ³•è§£é‡Šåˆ—è¡¨
        """
        queue_file = Path(CONFIG['queue_file'])

        # è¯»å–ç°æœ‰é˜Ÿåˆ—
        existing_queue = []
        if queue_file.exists():
            with open(queue_file, 'r', encoding='utf-8') as f:
                existing_queue = json.load(f)

        # è¿‡æ»¤æ–°é¡¹ç›®
        new_items = []
        for interp in interpretations:
            if self.is_new_interpretation(interp['title'], interp['date']):
                new_items.append(interp)

        # åˆå¹¶å¹¶ä¿å­˜
        if new_items:
            updated_queue = existing_queue + new_items
            with open(queue_file, 'w', encoding='utf-8') as f:
                json.dump(updated_queue, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… å·²æ·»åŠ  {len(new_items)} ä¸ªæ–°å¸æ³•è§£é‡Šåˆ°é˜Ÿåˆ—")
            logger.info(f"é˜Ÿåˆ—æ–‡ä»¶ï¼š{queue_file.absolute()}")

            # å‘é€é€šçŸ¥
            self._send_notification(new_items)
        else:
            logger.info("ğŸ“­ æ²¡æœ‰å‘ç°æ–°çš„å¸æ³•è§£é‡Š")

        return len(new_items)

    def _send_notification(self, new_items):
        """
        å‘é€æ›´æ–°é€šçŸ¥

        Args:
            new_items: æ–°å¸æ³•è§£é‡Šåˆ—è¡¨
        """
        message = f"""
ğŸ”” å‘ç° {len(new_items)} ä¸ªæ–°å¸æ³•è§£é‡Šï¼

"""

        for item in new_items:
            message += f"""
æ ‡é¢˜ï¼š{item['title']}
å‘å¸ƒæ—¥æœŸï¼š{item['date']}
é“¾æ¥ï¼š{item['link']}
"""

        message += f"""
ç›‘æµ‹æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆæ¨¡å—ï¼š
cd tools/generator && python draft-generator.py --queue
"""

        logger.info("\n" + "="*50)
        logger.info(message)
        logger.info("="*50)

        # ä¿å­˜é€šçŸ¥åˆ°æ–‡ä»¶
        notification_file = Path("NOTIFICATION.md")
        with open(notification_file, 'w', encoding='utf-8') as f:
            f.write(message)

        logger.info(f"ğŸ“ é€šçŸ¥å·²ä¿å­˜åˆ°ï¼š{notification_file.absolute()}")


def main():
    """ä¸»ç¨‹åº"""
    logger.info("="*50)
    logger.info("æœ€é«˜æ³•é™¢å¸æ³•è§£é‡Šç›‘æµ‹å·¥å…·å¯åŠ¨")
    logger.info("="*50)

    # åˆ›å»ºç›‘æµ‹å™¨
    monitor = CourtMonitor()

    # è·å–æœ€è¿‘30å¤©çš„å¸æ³•è§£é‡Š
    interpretations = monitor.fetch_interpretations(days=30)

    if interpretations:
        # ä¿å­˜åˆ°é˜Ÿåˆ—
        new_count = monitor.save_to_queue(interpretations)

        if new_count > 0:
            logger.info(f"\nâœ… ç›‘æµ‹å®Œæˆï¼å‘ç° {new_count} ä¸ªæ–°å¸æ³•è§£é‡Š")
        else:
            logger.info("\nğŸ“­ ç›‘æµ‹å®Œæˆï¼æ²¡æœ‰å‘ç°æ–°çš„å¸æ³•è§£é‡Š")
    else:
        logger.warning("\nâš ï¸ æœªèƒ½è·å–å¸æ³•è§£é‡Šåˆ—è¡¨")

    logger.info("="*50)
    logger.info("ç›‘æµ‹ç»“æŸ")
    logger.info("="*50)


if __name__ == '__main__':
    main()
